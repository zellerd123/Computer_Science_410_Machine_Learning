{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4efb1406-fcb6-4814-a2c6-27651b4e19b6",
   "metadata": {},
   "source": [
    "# Homework 2: Classification Competition\n",
    "\n",
    "#### COSC 410: Spring 2024, Colgate University"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76db66a5-e628-452e-8673-df97152dad07",
   "metadata": {},
   "source": [
    "See HW2.pdf for more details. **Due Feb 26**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "abad0cb6-265e-4080-990e-6ad371907f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import make_classification\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fd2665-1560-42c9-bf5c-04b9092aa6ca",
   "metadata": {},
   "source": [
    "### ML Task Description\n",
    "\n",
    "The `Lab3_train.csv` file contains 10 years worth of daily weather observations from locations\n",
    "across Australia, one row per day. It contains a column registering a binary label for each observation (`RainTomorrow`) a `1` if it rained\n",
    "on the following day or a `0` if it did not. Your goal will be to create a ML model that, when given a\n",
    "new weather observations, can predict whether it will rain on the day after\n",
    "the observation. In other words, can you use machine learning to predict if it will rain tomorrow\n",
    "based on the weather today?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77714c60-606a-42d7-b291-bc582aed0d41",
   "metadata": {},
   "source": [
    "### Open Ended Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed301a57-92c5-4119-9261-557ef715d267",
   "metadata": {},
   "source": [
    "Answer the following questions (referencing your code in this notebook when appropriate)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22e2687-be86-4382-a23c-0ae997bc8576",
   "metadata": {},
   "source": [
    "1. Describe the data preprocessing steps your pipeline performs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd5cee2-f42c-4b22-9e83-7a6e812b9542",
   "metadata": {},
   "source": [
    "My program iterates through the data, filling in the mode for catagorical empty data and the median for numerical data. Then it uses a scale to turn the categorical data into numerical indices. I tried using a KNNimputer to make the program run better, but I ran into a couple of issues. The biggest being runtime. Using k=5, I couldn't get the program to end, with k=1, it still took 10 minutes, and the results were frankly suboptimal. I'm sure with a high powered computer, this would be the better method, but since I can't test different values of K, it was extremely inefficient. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae310aed-4834-4133-94ff-82ff74261e7e",
   "metadata": {},
   "source": [
    "2. What different models did you try to improve your performance? How did they perform relative to each other?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3651b0-f186-4c76-8622-06ce9271d6c6",
   "metadata": {},
   "source": [
    "I tried a bunch of different models for this. I tried KNNs, Logistic Regressions, Random Forests, and Random Forest with Gradient Boosting and SVMs. They all performed around ~.45-.6 F1 score. Except for SVM, which had a very high precision but very low recall that I had trouble modifying to get good results. Overall, the logistic regression performs the best, but by a very small margin. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cd014a-c01c-4996-88be-da304c28b232",
   "metadata": {},
   "source": [
    "3. What different hyperparameters did you attempt to optimize for the model you submitted? What values did you choose in the end?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853a66fb-599b-4eda-bc51-c95ffce5240c",
   "metadata": {},
   "source": [
    "I've been tinkering with just about every hyperparameter I can get my hands on. Right now, here are my current values: LogisticRegression(max_iter = 1000, multi_class = 'multinomial', C = 10, solver = 'saga', class_weight = 'balanced', penalty = 'elasticnet', l1_ratio = 1). Some of the params don't really make a difference, but taking them out didn't help/hurt it, so left in for now. There might be some more variations by the very end, but this is where I am at right now. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0b58fc-f953-4a34-8133-4a5f06dd8cf9",
   "metadata": {},
   "source": [
    "4. Did model selection or hyperparameter optimization make the most difference for improving model performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee84b60e-3aaf-40bf-83dc-9b18fffdd7ac",
   "metadata": {},
   "source": [
    "Its hard to say which made the bigger difference, as each model has different hyperparameters. Both are super important, and identifying which made the most difference is a little difficult to wrap my head around. Choosing the right model is important, and then tuning the parameters after is how it succeeds. Also, I was able to get more success by changing the binary classifier threshold from .5 to .64, which brought precision and recall to ~the same number, and increased the f1 score by .02."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b72e6ab-58ed-499b-aca0-73bcbbb5b5c9",
   "metadata": {},
   "source": [
    "YOUR ANSWER GOES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd327e3-99f3-477d-9b21-8e54d62552d8",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908d2bf2-dd91-43d5-894c-4f7ce6cfcf04",
   "metadata": {},
   "source": [
    "Your initial task is to preprocess this dataset. This includes resolving missing features, encoding nominal features, and appropriately scaling all features. You'll implement the function `preprocess`. Blocks below point out some useful tricks for approaching this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "239cc44e-2e47-4c2c-bd69-419aaa6164c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Lab3_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "cc41eafb-c3ad-423b-9095-2ba25dcdd47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\" x' = (x - mean)/sd \n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe to scale \n",
    "    Returns:\n",
    "        pd.DataFrame having standardized features\n",
    "        \n",
    "    Note: Only apply after steps 1 and 2\"\"\"\n",
    "    \n",
    "    nonLabel = list(filter(lambda x: x != 'RainTomorrow', df.columns))\n",
    "    \n",
    "    # We don't want to scale our prediction \n",
    "    subset = df[nonLabel]\n",
    "    # Mapping feature to it's mean and sd\n",
    "    means = dict(subset.mean())\n",
    "    sds = dict(subset.std())\n",
    "\n",
    "    # Loop through and do the math\n",
    "    for col in means:\n",
    "        df[col] = (df[col] - means[col])/sds[col]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "839ecee7-73f9-41c8-baa7-71b86b49100e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(filename: str) -> pd.DataFrame: \n",
    "    \"\"\" Preprocess your data \n",
    "\n",
    "    Args:\n",
    "        filename (str): Name of the csv file containing the data\n",
    "\n",
    "    Returns: \n",
    "        pd.DataFrame: Dataframe with relevent preprocessing applied\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(filename)\n",
    "    for col in df.select_dtypes(include=['float64', 'int64']).columns: \n",
    "        df[col].fillna(df[col].median(), inplace = True)\n",
    "  \n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        df[col].fillna(df[col].mode()[0], inplace = True)\n",
    "    for col in df.select_dtypes(include=['object']).columns: \n",
    "        df[col],_ = pd.factorize(df[col])\n",
    "\n",
    "    df = scale(df)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "f3d3f495-cedc-4471-9184-cdf37d573a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preprocess('Lab3_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc69af7-26a2-4ba7-997b-b6a043d5e4ab",
   "metadata": {},
   "source": [
    "## Train a Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "f8da3b88-3581-4c92-91cf-d29fe1c5f732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict(train_fname: str, test_fname: str) -> np.array: \n",
    "    \"\"\" Fit a logistic regression model and return its predictions on test data \n",
    "\n",
    "    Args:\n",
    "        train_fname (str): Name of the training file \n",
    "        test_fname (str): Name of the testing file\n",
    "    Returns:\n",
    "        np.array: Predictions of the model on test data\n",
    "\n",
    "    Note: \n",
    "        Make sure you preprocess both your train and test data!\"\"\"\n",
    "    #scaler = MinMaxScaler()\n",
    "    train = preprocess(train_fname)\n",
    "    test = preprocess(test_fname)\n",
    "    #kept_features = ['Humidity3pm','Sunshine', 'Pressure3pm', 'Cloud3pm']\n",
    "    #x_train = train[kept_features]\n",
    "    x_train = train.drop('RainTomorrow', axis = 1)\n",
    "    y_train = train['RainTomorrow']\n",
    "\n",
    "    #x_test = test[kept_features]\n",
    "    x_test = test.drop('RainTomorrow', axis = 1)\n",
    "    model = LogisticRegression(max_iter = 1000, multi_class = 'multinomial', C = 100, solver = 'saga', class_weight = 'balanced', penalty = 'elasticnet', l1_ratio = 1)\n",
    "    model.fit(x_train, y_train)\n",
    "    probabilities = model.predict_proba(x_test)[:, 1] \n",
    "    y_pred = (probabilities >= .64)\n",
    "    #y_pred = model.predict(x_test)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "d6b209bf-22d6-4151-9c3e-de72bb0bc37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict_2(train_fname: str, test_fname: str) -> np.array: \n",
    "    \"\"\" Fit a logistic regression model and return its predictions on test data \n",
    "\n",
    "    Args:\n",
    "        train_fname (str): Name of the training file \n",
    "        test_fname (str): Name of the testing file\n",
    "    Returns:\n",
    "        np.array: Predictions of the model on test data\n",
    "\n",
    "    Note: \n",
    "        Make sure you preprocess both your train and test data!\"\"\"\n",
    "    train = preprocess(train_fname)\n",
    "    test = preprocess(test_fname)\n",
    "    #kept_features = ['Humidity3pm','Sunshine', 'Pressure3pm', 'Cloud3pm']\n",
    "    #x_train = train[kept_features]\n",
    "    x_train = train.drop('RainTomorrow', axis = 1)\n",
    "    y_train = train['RainTomorrow']\n",
    "\n",
    "    #x_test = test[kept_features]\n",
    "    x_test = test.drop('RainTomorrow', axis = 1)\n",
    "    model = SVC(kernel = 'poly', class_weight = 'balanced', C = 100, max_iter = 3000)\n",
    "    #model = LogisticRegression(max_iter = 1000)\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "022adec9-0cb9-47d2-980e-f69ae8426fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict3(train_fname: str, test_fname: str) -> np.array: \n",
    "    \"\"\" Fit a logistic regression model and return its predictions on test data \n",
    "\n",
    "    Args:\n",
    "        train_fname (str): Name of the training file \n",
    "        test_fname (str): Name of the testing file\n",
    "    Returns:\n",
    "        np.array: Predictions of the model on test data\n",
    "\n",
    "    Note: \n",
    "        Make sure you preprocess both your train and test data!\"\"\"\n",
    "    train = preprocess(train_fname)\n",
    "    x_train = train.drop('RainTomorrow', axis = 1)\n",
    "    y_train = train['RainTomorrow']\n",
    "    test = preprocess(test_fname)\n",
    "    x_test = test.drop('RainTomorrow', axis = 1)\n",
    "    model = KNeighborsClassifier(n_neighbors = 100)\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "73c6455c-c1d0-42a3-ae15-8cb9cd3f1489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict4(train_fname: str, test_fname: str) -> np.array: \n",
    "    \"\"\" Fit a logistic regression model and return its predictions on test data \n",
    "\n",
    "    Args:\n",
    "        train_fname (str): Name of the training file \n",
    "        test_fname (str): Name of the testing file\n",
    "    Returns:\n",
    "        np.array: Predictions of the model on test data\n",
    "\n",
    "    Note: \n",
    "        Make sure you preprocess both your train and test data!\"\"\"\n",
    "    train = preprocess(train_fname)\n",
    "    x_train = train.drop('RainTomorrow', axis = 1)\n",
    "    y_train = train['RainTomorrow']\n",
    "    test = preprocess(test_fname)\n",
    "    x_test = test.drop('RainTomorrow', axis = 1)\n",
    "    model = RandomForestClassifier(n_estimators = 100, random_state = 0)\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "8f3a4079-1ff9-4cb9-af06-d589c911d751",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "def fit_predict5(train_fname: str, test_fname: str) -> np.array: \n",
    "    \"\"\" Fit a logistic regression model and return its predictions on test data \n",
    "\n",
    "    Args:\n",
    "        train_fname (str): Name of the training file \n",
    "        test_fname (str): Name of the testing file\n",
    "    Returns:\n",
    "        np.array: Predictions of the model on test data\n",
    "\n",
    "    Note: \n",
    "        Make sure you preprocess both your train and test data!\"\"\"\n",
    "    train = preprocess(train_fname)\n",
    "    x_train = train.drop('RainTomorrow', axis = 1)\n",
    "    y_train = train['RainTomorrow']\n",
    "    test = preprocess(test_fname)\n",
    "    x_test = test.drop('RainTomorrow', axis = 1)\n",
    "    model = GradientBoostingClassifier(n_estimators = 100, random_state = 0, learning_rate = .1)\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "a17a29de-e77b-4ad3-9956-34ae4a646ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6071495066095699, 0.6457425742574258, 0.6258516457153824)\n"
     ]
    }
   ],
   "source": [
    "def score(test_fname: str, Y_pred: np.array) -> list[float]:\n",
    "    test = preprocess(test_fname)\n",
    "    Y = test[test.columns[test.columns.isin(['RainTomorrow'])]]\n",
    "\n",
    "    precision = metrics.precision_score(Y, Y_pred)\n",
    "    recall = metrics.recall_score(Y, Y_pred)\n",
    "    f1 = metrics.f1_score(Y, Y_pred)\n",
    "\n",
    "    return precision, recall, f1\n",
    "\n",
    "Y_pred = fit_predict(\"Lab3_train.csv\", \"Lab3_valid.csv\")\n",
    "print(score('Lab3_valid.csv', Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1736edc-74ad-475a-b12e-f1ac5c7d5680",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
